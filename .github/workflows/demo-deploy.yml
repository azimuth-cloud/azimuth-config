name: Deploy External
on: workflow_call

env:
  OS_CLOUD: openstack
  OS_CLIENT_CONFIG_FILE: ${{ github.workspace }}/clouds.yml
  AZIMUTH_CONFIG_ENVIRONMENT: ci
  AZIMUTH_ENVIRONMENT: ci-${{ github.run_id }}

jobs:
  test_deployment:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.sha }}
      
      - name: Copy cloud creds to file
        run: 'echo "$CLOUD" > clouds.yml'
        shell: bash
        env:
          CLOUD: ${{ secrets.CLOUD }}
            
      - uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          check-latest: true

      - name: Deploy Azimuth
        id: deploy
        run: ./bin/ci-exec provision
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.ARCUS_S3_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ARCUS_S3_SECRET_KEY }}

      - name: Check expected alerts are pending or firing
        run: |
          source ./bin/activate $AZIMUTH_CONFIG_ENVIRONMENT $AZIMUTH_ENVIRONMENT \
          && ./bin/check-alerts
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.ARCUS_S3_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ARCUS_S3_SECRET_KEY }}

      - name: Destroy Azimuth
        # NOTE: This step won't teardown the demo deployment if the CI fails,
        # which allows us to then access the failed partial deployment to debug.
        # Assuming you have Arcus cloud access, the seed node for a given CI run
        # can be accessed by activating the CI environment locally with
        # `source ./bin/activate ci ci-<github-workflow-run-id>`
        # then running the seed-ssh script as normal.
        if: ${{ always() }}
        run: ./bin/ci-exec destroy
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.ARCUS_S3_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ARCUS_S3_SECRET_KEY }}
