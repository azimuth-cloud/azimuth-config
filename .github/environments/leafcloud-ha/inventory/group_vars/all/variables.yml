# Unset the network ID so that a network + router are provisioned
infra_network_id:

# Unset the infra IP so we can use the ingress IP for the ingress controller
infra_fixed_floatingip:
capi_cluster_addons_ingress_load_balancer_ip: "{{ lookup('env', 'INGRESS_IP') }}"

# Make sure we pick flavors that keep the costs down
#   The flavor to use for the seed VM
infra_flavor_id: ec1.medium  # 2 vCPUs, 4GB RAM @ leaf site
#   The flavor to use for the control plane nodes
capi_cluster_control_plane_flavor: ec1.medium  # 2 vCPUs, 4GB RAM @ leaf site
#   The flavor to use for worker nodes
capi_cluster_worker_flavor: en1.medium  # 2 vCPUs, 8GB RAM @ leaf site

# Although this is a "HA" test, what we are really testing is the spawning
# of the CAPI cluster and deployment of Azimuth onto that
# So one control plane node is sufficient for that
capi_cluster_control_plane_count: 1
capi_cluster_worker_count: 2

# Don't use explicit AZs for Kubernetes nodes
capi_cluster_control_plane_omit_failure_domain: true
capi_cluster_worker_failure_domain: null

# Leafcloud doesn't use the default 'nova' AZ for volumes
capi_cluster_root_volume_availability_zone: europe-nl-ams1
capi_cluster_addons_csi_cinder_availability_zone: europe-nl-ams1

# Use the unencrypted volume type for Kubernetes volumes
capi_cluster_root_volume_type: unencrypted
capi_cluster_addons_csi_cinder_volume_type: unencrypted

# Use a single replica for Consul
# The risk of failed upgrades is too great, and it is going away soon
consul_server_replicas: 1

# Enable Velero just to check that installation works
velero_enabled: true
velero_s3_url: https://required-but-not-used.com
velero_bucket_name: not-used
velero_backup_schedule_enabled: true
velero_backup_schedule_name: default
velero_backup_schedule_timings: "0 0 * * *"
velero_backup_schedule_ttl: "168h"
velero_aws_access_key_id: required-but-not-used
velero_aws_secret_access_key : required-but-not-used
