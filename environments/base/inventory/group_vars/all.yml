#####
# This file contains defaults that apply to all hosts
#####

# Convert envvars for the active environment into Ansible variables
azimuth_environment: "{{ lookup('env', 'AZIMUTH_ENVIRONMENT') }}"
azimuth_config_root: "{{ lookup('env', 'AZIMUTH_CONFIG_ROOT') }}"
azimuth_config_environment: "{{ lookup('env', 'AZIMUTH_CONFIG_ENVIRONMENT') }}"
azimuth_config_environment_root: "{{ lookup('env', 'AZIMUTH_CONFIG_ENVIRONMENT_ROOT') }}"

# If the task is running locally, use local work and bin directories
# Otherwise, use directories on the host
local_bin_directory: "{{ (azimuth_config_root, '.bin') | path_join }}"
local_work_directory: "{{ (azimuth_config_root, '.work', azimuth_environment) | path_join }}"
bin_directory: "{{ local_bin_directory if ansible_connection == 'local' else '/usr/local/bin' }}"
work_directory: "{{ local_work_directory if ansible_connection == 'local' else ansible_env.HOME }}"

# Use the configured work directory for image download and convert
community_images_workdir: "{{ (work_directory, 'images') | path_join }}"

# Use the configured bin and work directories for Terraform
terraform_binary_directory: "{{ bin_directory }}"
# Use the local work directory for the Terraform project
terraform_project_path: "{{ (work_directory, 'terraform') | path_join }}"
# Get the Terraform backend type from the environment variables
terraform_backend_type: "{{ lookup('env', 'AZIMUTH_TERRAFORM_BACKEND_TYPE') | default('local', True) }}"
# By default, assume all Terraform config comes from environment variables
terraform_backend_config: {}

# Use the configured work directory for prepping manifests
clusterapi_kustomization_directory: "{{ (work_directory, 'clusterapi') | path_join }}"
pgo_kustomization_directory: "{{ (work_directory, 'postgres-operator') | path_join }}"
keycloak_operator_kustomization_directory: "{{ (work_directory, 'keycloak-operator') | path_join }}"
awx_operator_directory: "{{ (work_directory, 'awx-operator') | path_join }}"
# Use the configured work directory for the test suite
generate_tests_suite_directory: "{{ (work_directory, 'test-suite') | path_join }}"

# Enable cert-manager by default
# By default, a cluster issuer will be created that uses Let's Encrypt to issue certificates
certmanager_enabled: yes
# By default, only enable the cluster issuer when not using a wildcard certificate
certmanager_acmehttp01issuer_enabled: "{{ not ingress_tls_wildcard_certificate }}"

# Create a mirror registry in Harbor for public Docker Hub images by default
harbor_enabled: yes
harbor_proxy_cache_default_projects:
  docker.io:
    name: dockerhub-public
    type: docker-hub
    url: https://hub.docker.com
harbor_proxy_cache_extra_projects: {}
harbor_proxy_cache_projects: >-
  {{ harbor_proxy_cache_default_projects | combine(harbor_proxy_cache_extra_projects) }}

# Indicates whether to install a Grafana to show cloud metrics
cloud_metrics_enabled: no

# Indicates whether to enable Velero for backup and restore
velero_enabled: no

# Azimuth features to enable
azimuth_apps_enabled: yes
azimuth_kubernetes_enabled: yes
azimuth_clusters_enabled: yes

# The base domain for Azimuth ingress resources
# This should be set by the concrete environment
ingress_base_domain: "{{ undef(hint = 'ingress_base_domain is required') }}"
# The subdomain that should be used for the portal
ingress_azimuth_portal_subdomain: portal
# The subdomain that should be used for the registrar
ingress_zenith_registrar_subdomain: registrar
# The subdomain that should be used for the Harbor core
ingress_harbor_core_subdomain: registry
# The subdomain that should be used for the Harbor notary
ingress_harbor_notary_subdomain: notary
# The subdomain that should be used for Keycloak
ingress_keycloak_subdomain: identity

# Annotations for Azimuth ingress resources
ingress_annotations:
  # Use longer timeouts by default to try to prevent gateway timeouts for CaaS operations
  nginx.ingress.kubernetes.io/proxy-connect-timeout: "600"
  nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
  nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
  nginx.ingress.kubernetes.io/proxy-buffer-size: 16k

# A pre-existing wildcard certificate and key for the base domain
# These should be dropped in to the environment as {environment}/tls/tls.{crt,key}
#   The certificate file is allowed not to exist, as usage is gated on it
ingress_tls_wildcard_certificate_file: "{{ (azimuth_config_environment_root, 'tls', 'tls.crt') | path_join }}"
#   We ignore errors from the lookup as the file is allowed not to exist
#   In that case, we use cert-manager annotations if available, else TLS is disabled
ingress_tls_wildcard_certificate: "{{ lookup('file', ingress_tls_wildcard_certificate_file, errors = 'ignore') or None }}"
#   The key file must exist, but is only used when the certificate file is present
ingress_tls_wildcard_key_file: "{{ (azimuth_config_environment_root, 'tls', 'tls.key') | path_join }}"
ingress_tls_wildcard_key: "{{ lookup('file', ingress_tls_wildcard_key_file) }}"

# TLS-related annotations, e.g. for cert-manager
# If cert-manager + the cluster issuer are enabled, the required annotation to use the issuer
# will be picked up by default
# If specified, the wildcard certificate will take precedence over this
ingress_tls_annotations: >-
  {{
    certmanager_ingress_annotations
    if not ingress_tls_wildcard_certificate and certmanager_ingress_annotations is defined
    else {}
  }}

# Indicates if TLS should be enabled
ingress_tls_enabled: "{{ not not (ingress_tls_wildcard_certificate or ingress_tls_annotations) }}"
# The name of the secret containing the wildcard certificate
ingress_tls_secret_name: "{{ 'azimuth-tls' if ingress_tls_wildcard_certificate else None }}"

# Infer the OpenStack auth URL from the configured credential by default
__os_cloud: >-
  {{-
    lookup(
      'env',
      'OS_CLOUD',
      default = undef(hint = 'OS_CLOUD is not set')
    )
  }}
#   This is the local path to the application credential
__os_clouds_file: >-
  {{-
    lookup(
      'env',
      'OS_CLIENT_CONFIG_FILE',
      default = undef(hint = 'OS_CLIENT_CONFIG_FILE is not set')
    )
  }}
__os_auth_url: >-
  {{-
    lookup('file', __os_clouds_file) |
      from_yaml |
      json_query('clouds.' + __os_cloud + '.auth.auth_url')
  }}
azimuth_openstack_auth_url: "{{ __os_auth_url | trim('/') }}/v3"

# Use the current project ID for the HA CAPI cluster
capi_cluster_openstack_project_id: >-
  {{-
    lookup('pipe', 'openstack token issue -f value -c project_id')
  }}

# If there is only one external network, use it by default
__os_external_networks: >-
  {{-
    lookup('pipe', 'openstack network list --external -f json') |
      from_json |
      map(attribute = 'ID')
  }}
infra_external_network_id: >-
  {{-
    __os_external_networks[0]
    if __os_external_networks | length == 1
    else undef(hint = 'Unable to determine external network ID')
  }}

# If there is only one load balancer provider, use it by default
# Note that 'octavia' is excluded as it is an alias of 'amphora'
__os_loadbalancer_providers: >-
  {{-
    lookup('pipe', 'openstack loadbalancer provider list -f json') |
      from_json |
      map(attribute = 'name') |
      reject('equalto', 'octavia')
  }}
openstack_loadbalancer_provider: >-
  {{-
    __os_loadbalancer_providers[0]
    if __os_loadbalancer_providers | length == 1
    else undef(hint = 'Unable to determine load balancer provider')
  }}
# Only set this variable if the selected provider is not amphora, otherwise we break existing deployments
capi_cluster_apiserver_loadbalancer_provider: >-
  {{-
    openstack_loadbalancer_provider
    if openstack_loadbalancer_provider != "amphora"
    else None
  }}
capi_cluster_addons_openstack_loadbalancer_provider: >-
  {{- openstack_loadbalancer_provider }}
azimuth_capi_operator_capi_helm_openstack_loadbalancer_provider: >-
  {{- openstack_loadbalancer_provider }}
