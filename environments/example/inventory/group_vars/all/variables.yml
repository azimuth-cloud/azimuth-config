#####
# Configuration for the seed node (HA) or single node
#####

# The ID of an existing network to create the node on
infra_network_id: "<internal network id>"
# OR
# The CIDR of the subnet that should be created
infra_network_cidr: 192.168.100.0/24
# The ID of the external network to connect to via a router
infra_external_network_id: "<external network id>"

# The fixed floating IP to associate with the machine
# This IP must be pre-allocated to the project
# For a single node deployment, this IP should have the wildcard ingress domain assigned to it
infra_fixed_floatingip: "<pre-allocated floating ip>"
# OR
# The name of the floating IP pool to allocate a floating IP from
infra_floatingip_pool: "<floating ip pool>"
# OR
# The ID of a provisioning network that will be used to access the seed node
infra_provisioning_network_id: "<provisioning network id>"

# The key of an Ubuntu 20.04 image in the infra_community_images variable to use for the node
infra_image_key: ubuntu_2004_20220411
# OR
# The image id of an Ubuntu 20.04 image to use for the node
infra_image_id: "<image id>"

# The id of the flavor to use for the node
# For a seed node for an HA cluster, 8GB RAM is fine (maybe even 4GB)
# For a single node deployment, >= 16GB RAM is recommended
infra_flavor_id: "<flavor id>"

# The size in GB for the data volume
# This will hold all cluster data, including Kubernetes resources, and also PVC data
infra_data_volume_size: 100

#####
# Configuration for the HA cluster
#####

# The project id in which the cluster will be deployed
# Must correspond to the clouds.yaml for the environment
capi_cluster_openstack_project_id: "<openstack project id>"
# The Kubernetes version that will be used for the HA cluster
capi_cluster_kubernetes_version: 1.22.8
# The ID of the image that will be used
capi_cluster_machine_image_id: "{{ infra_community_image_info.kube_1_22_8 }}"
# The name of the flavor to use for control plane nodes
capi_cluster_control_plane_flavor: "<flavor name>"
# The name of the flavor to use for worker nodes
capi_cluster_worker_flavor: "<flavor name>"
# The number of worker nodes
capi_cluster_worker_count: 3
# The fixed floating IP to associate with the load balancer for the ingress controller
# This IP must be pre-allocated to the project and should have the wildcard ingress domain assigned to it
capi_cluster_addons_ingress_load_balancer_ip: "<pre-allocated floating ip>"

#####
# Ingress configuration
#####
# The base domain to use for ingress resources
ingress_base_domain: "<base domain>"

# Indicates if cert-manager should be enabled
# Currently, TLS is enabled for ingress iff cert-manager is enabled
certmanager_enabled: yes

# Indicates if Harbor should be enabled to provide pull-through caches
harbor_enabled: no

#####
# Azimuth configuration
#####
# Indicates if the Zenith app proxy should be enabled
azimuth_apps_enabled: yes
# Indicates if Kubernetes support should be enabled
azimuth_kubernetes_enabled: yes
# Indicates if Cluster-as-a-Service (CaaS) should be enabled
azimuth_clusters_enabled: yes

# The name of the current cloud
azimuth_current_cloud_name: example
# The label for the current cloud
azimuth_current_cloud_label: Example
# The auth URL for the target OpenStack cloud
azimuth_openstack_auth_url: https://cloud.example.com:5000/v3

# If CaaS is enabled and the StackHPC Slurm appliance is enabled (the default), this
#Â should be the id of a Rocky 8 image that will be used for Slurm clusters
azimuth_caas_stackhpc_slurm_appliance_rocky8_image: "{{ infra_community_image_info.rocky_8_5_20211114 }}"
