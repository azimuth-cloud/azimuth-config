#####
# This file, combined with secrets.yml, shows an example configuration for a
# minimal, but still best-practice, Azimuth deployment on a "well-behaved" cloud
#
# https://stackhpc.github.io/azimuth-config/best-practice/
#
# It is recommended to read the "Configuration" section of the Azimuth Operator
# Documentation in full to understand all the available options
#
# https://stackhpc.github.io/azimuth-config/configuration/
#####

## Configuration for OpenTofu state
## https://stackhpc.github.io/azimuth-config/repository/opentofu/

# The Terraform backend type to use (HTTP and S3 supported)
terraform_backend_type: "<http or s3>"

# The backend configuration (depends on the selected backend type)
terraform_backend_config: {}


## Configuration for the seed node (HA) or single node deployment
## https://stackhpc.github.io/azimuth-config/configuration/02-deployment-method/

# The ID of the external network to use
# This network must provide _egress_ to the internet
# https://stackhpc.github.io/azimuth-config/configuration/01-prerequisites/#networking
infra_external_network_id: "<network id>"

# The id of the flavor to use for the node
# For a seed node for an HA cluster, 8GB RAM is fine (maybe even 4GB)
# For a single node deployment, >= 16GB RAM is recommended
infra_flavor_id: "<flavor id>"

# The size of the volume to use for K3S cluster data
infra_data_volume_size: 100

# SINGLE NODE DEPLOYMENT ONLY
# The fixed floating IP to associate with the machine
# Must be pre-allocated to the project and have the wildcard ingress domain assigned to it
# infra_fixed_floatingip: "<pre-allocated floating ip>"


## Configuration for the HA cluster
## https://stackhpc.github.io/azimuth-config/configuration/02-deployment-method/
## https://stackhpc.github.io/azimuth-config/configuration/03-kubernetes-config/

# The name of the flavor to use for control plane nodes
# A flavor with at least 2 CPUs, 8GB RAM and 100GB root disk is recommended
capi_cluster_control_plane_flavor: "<flavor name>"

# The name of the flavor to use for worker nodes
# A flavor with at least 4 CPUs, 16GB RAM and 100GB root disk is recommended
capi_cluster_worker_flavor: "<flavor name>"

# The number of worker nodes
capi_cluster_worker_count: 3

# The floating IP to which to wildcard DNS entry has been assigned
capi_cluster_addons_ingress_load_balancer_ip: "<pre-allocated floating ip>"


## Target cloud configuration
## https://stackhpc.github.io/azimuth-config/configuration/04-target-cloud/

# The name of the current cloud
azimuth_current_cloud_name: example

# The label for the current cloud
azimuth_current_cloud_label: Example


## Ingress configuration
## https://stackhpc.github.io/azimuth-config/configuration/06-ingress/

# The base domain to use for ingress resources
ingress_base_domain: "<base domain>"


## Persistence and retention for monitoring (HA only)
## https://stackhpc.github.io/azimuth-config/configuration/14-monitoring/#persistence-and-retention

# Prometheus retention and volume size
capi_cluster_addons_monitoring_prometheus_retention: 90d
capi_cluster_addons_monitoring_prometheus_volume_size: 50Gi

# Loki retention and volume size
capi_cluster_addons_monitoring_loki_retention: 744h
capi_cluster_addons_monitoring_loki_volume_size: 50Gi


## Disaster recovery
## https://stackhpc.github.io/azimuth-config/configuration/15-disaster-recovery/

# Enable Velero for backup
velero_enabled: true

# The URL of the S3 endpoint to use for backups
velero_s3_url: "<endpoint URL>"

# The name of the S3 bucket to use for backups (must already exist)
velero_bucket_name: "<bucket name>"
