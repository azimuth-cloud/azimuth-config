---

# Use the first available external network
infra_external_network_id: >-
  {{
    lookup('pipe', 'openstack network list --external -f json') |
      from_json |
      first |
      default(undef(hint = 'Unable to find external network')) |
      json_query('ID')
  }}

# Hard-code network id instead
# infra_external_network_id: ee54f79e-d33a-4866-8df0-4a4576d70243

# Need extra var since leafcloud has multiple networks of type 'external'
# azimuth_capi_operator_external_network_id: ee54f79e-d33a-4866-8df0-4a4576d70243

# Pick suitable flavors from the available flavors
#   Only consider flavors with at least 2 CPUs and 20GB disk
__os_flavors: >-
  {{
    lookup('pipe', 'openstack flavor list -f json') |
      from_json |
      selectattr('Disk', '>=', 20) |
      selectattr('VCPUs', '>=', 2)
  }}
# For the infra, we need at least 8GB RAM, but 16GB is better, plus at least 4 CPUs
infra_flavor_id: >-
  {{-
    __os_flavors |
      selectattr('RAM', '>=', 8192) |
      selectattr('RAM', '<=', 16384) |
      sort(attribute = 'RAM', reverse = True) |
      first |
      default(undef(hint = 'Unable to determine a suitable infra_flavor_id')) |
      json_query('ID')
  }}

# For Slurm, we need at least 4GB RAM
# Use the same flavor for login and control nodes
azimuth_caas_stackhpc_slurm_appliance_login_flavor_name: >-
  {{-
    __os_flavors |
      selectattr('RAM', '>=', 4096) |
      sort(attribute = 'RAM,Ephemeral') |
      first |
      default(undef(hint = 'Unable to determine a suitable azimuth_caas_stackhpc_slurm_appliance_login_flavor_name')) |
      json_query('Name')
  }}
azimuth_caas_stackhpc_slurm_appliance_control_flavor_name: >-
  {{- azimuth_caas_stackhpc_slurm_appliance_login_flavor_name }}

# Upload images as private
# CaaS/Kubernetes will only work within the tenancy in which Azimuth is deployed
community_images_default_visibility: private
# However don't assume we are in control of the images, e.g. if there is another
# Azimuth deployment on the same cloud
community_images_update_existing_visibility: false

# Disable HTTPS and certificate verification everywhere to avoid certificate issues
ingress_tls_enabled: false

# Disable SSL verification for OpenStack in case it uses a custom CA
azimuth_openstack_verify_ssl: false

azimuth_current_cloud_name: demo

# Use secrets that are not really secret for ease
harbor_admin_password: admin
harbor_secret_key: abcdefghijklmnop
awx_admin_password: admin
zenith_registrar_subdomain_token_signing_key: abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789AA
azimuth_secret_key: 9876543210ZYXWVUTSRQPONMLKJIHGFEDCBAzyxwvutsrqponmlkjihgfedcda00

# Leafcloud doesn't use the default nova AZ - set explicitly for k8s worker nodes and Cinder CSI
# azimuth_capi_operator_capi_helm_worker_failure_domain: europe-nl-ams1
# azimuth_capi_operator_capi_helm_csi_cinder_default_availability_zone: europe-nl-ams1

# Use arm64 terraform since since my seed vm is hosted on MacOS
# terraform_architecture: arm64

# Enable kube-prometheus-stack integration for ingress-nginx service
ingress_nginx_release_overrides:
  controller:
    metrics:
      enabled: true
      serviceMonitor:
        enabled: true
        namespace: monitoring-system
        additionalLabels:
          release: kube-prometheus-stack

kube_prometheus_release_overrides:
  alertmanager:
    enabled: true
    config:
      global:
        slack_api_url: "{{ kube_prometheus_stack_alertmanager_slack_url }}" # Variable is defined in git-ignored ./secrets.yml
      route:
        receiver: 'slack-notifications'
        group_by: ['namespace']
      receivers:
      - name: 'null'
      - name: 'slack-notifications'
        slack_configs:
        - channel: '#general'
          send_resolved: true
  prometheus:
    prometheusSpec:
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: local-path
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 2Gi
